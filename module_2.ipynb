{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module utilizes the following dataset:\n",
    "https://www.kaggle.com/datasets/michaelbryantds/cpu-and-gpu-product-data\n",
    "\n",
    "It can either be imported using the code block below or downloaded manually as a .zip file. If you use the code below, make sure to run `pip install kagglehub` first.\n",
    "\n",
    "All uses of AI-generated code will be clearly labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\yalts\\.cache\\kagglehub\\datasets\\undefinenull\\million-song-dataset-spotify-lastfm\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"undefinenull/million-song-dataset-spotify-lastfm\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the specified path above and copy the file from that folder to the same directory as this Python file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j, tag2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tags):\n\u001b[0;32m     25\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[1;32m---> 26\u001b[0m                 tag_cooccurrence_matrix[tag_index[tag1]][tag_index[tag2]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Convert the co-occurrence matrix to a DataFrame\u001b[39;00m\n\u001b[0;32m     29\u001b[0m cooccurrence_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(tag_cooccurrence_matrix, index\u001b[38;5;241m=\u001b[39munique_tags, columns\u001b[38;5;241m=\u001b[39munique_tags)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the datasets, handling the empty file\n",
    "try:\n",
    "    listens_df = pd.read_csv(\"listens.csv\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    # Create dummy data for listens_df if the file is empty\n",
    "    listens_df = pd.DataFrame(columns=['track_id', 'user_id', 'playcount'])\n",
    "\n",
    "music_df = pd.read_csv(\"music.csv\")\n",
    "\n",
    "# Merge the DataFrames on 'track_id'\n",
    "merged_df = pd.merge(listens_df, music_df, on='track_id', how='inner')\n",
    "\n",
    "# Preprocess the tag data\n",
    "merged_df['tags'] = merged_df['tags'].astype(str).str.lower().str.strip()\n",
    "tag_lists = merged_df['tags'].str.split(', ')\n",
    "unique_tags = list(set(tag for tags in tag_lists for tag in tags))\n",
    "\n",
    "# Build the tag co-occurrence matrix\n",
    "tag_index = {tag: i for i, tag in enumerate(unique_tags)}\n",
    "tag_cooccurrence_matrix = [[0] * len(unique_tags) for _ in range(len(unique_tags))]\n",
    "\n",
    "for tags in tag_lists:\n",
    "    for i, tag1 in enumerate(tags):\n",
    "        for j, tag2 in enumerate(tags):\n",
    "            if i != j:\n",
    "                tag_cooccurrence_matrix[tag_index[tag1]][tag_index[tag2]] += 1\n",
    "\n",
    "# Convert the co-occurrence matrix to a DataFrame\n",
    "cooccurrence_df = pd.DataFrame(tag_cooccurrence_matrix, index=unique_tags, columns=unique_tags)\n",
    "\n",
    "# Convert to long format for easier use with NetworkX\n",
    "cooccurrence_df = cooccurrence_df.reset_index().rename(columns={'index': 'tag1'})\n",
    "cooccurrence_df_long = cooccurrence_df.melt(id_vars='tag1', var_name='tag2', value_name='weight')\n",
    "\n",
    "# Filter out self-loops and zero-weight edges\n",
    "cooccurrence_df_filtered = cooccurrence_df_long[(cooccurrence_df_long['tag1'] != cooccurrence_df_long['tag2']) & (cooccurrence_df_long['weight'] > 0)]\n",
    "\n",
    "# Display the first 5 rows of the filtered DataFrame\n",
    "print(cooccurrence_df_filtered.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
